# ğŸš¦ RiskRadar â€” IT Incident SLA Breach Risk Predictor

<p align="center">
  <b>An ML-based decision support system for IT incident triage</b><br/>
  Predicts SLA breach risk using historical incident event logs
</p>

---

## ğŸ§  Overview

RiskRadar is built around a very practical IT operations problem:

> *When hundreds or thousands of incidents are open, which ones are actually risky and need attention now?*

Most ITSM tools rely heavily on static priority labels. In reality, incidents evolve over time â€” reassignments, reopenings, long inactivity gaps, and category-specific patterns all affect whether an SLA breach is likely.

This project takes **real incident event history**, learns from it, and produces:
- A **probability-based SLA breach risk**
- Clear **risk bands (Low / Medium / High)**
- Simple **recommended actions**
- Visuals that help teams understand *where* and *why* risk is building up

This is not just a model â€” itâ€™s a small end-to-end system.

---

## ğŸ¯ Key Features

- ğŸ“Š SLA breach **probability prediction** (not just labels)
- ğŸ§© Feature engineering from event-level data
- ğŸšï¸ Probability calibration to align predictions with reality
- ğŸš¦ Risk banding (Low / Medium / High)
- ğŸ§  Human-readable explanations (facts-based)
- ğŸ“ˆ Interactive dashboard (Streamlit)
- ğŸ“¥ Downloadable scored dataset for further analysis

---

## ğŸ“š Dataset

**Incident management process enriched event log**  
Source: **UCI Machine Learning Repository**

This dataset comes from a real ServiceNow incident management system and contains anonymized, enriched event logs describing how incidents evolve over time.

**Citation (APA):**

> Amaral, C., Fantinato, M., & Peres, S. (2018). *Incident management process enriched event log*.  
> UCI Machine Learning Repository. https://doi.org/10.24432/C5754H

---

## ğŸ—ï¸ Project Structure

```
riskradar-it-incident-sla-risk/
â”‚
â”œâ”€â”€ app.py                  ğŸ–¥ï¸ Streamlit dashboard (main entry point)
â”œâ”€â”€ data_processing.py      ğŸ§¹ Data loading, cleaning, aggregation
â”œâ”€â”€ feature_engineering.py  ğŸ§  Feature creation for ML model
â”œâ”€â”€ model_training.py       ğŸ¤– Model training + calibration
â”œâ”€â”€ run_train.py            â–¶ï¸ Script to train and save model
â”œâ”€â”€ decision_logic.py       ğŸš¦ Risk bands + recommended actions
â”œâ”€â”€ llm_explainer.py        ğŸ’¬ Optional explanation layer (facts only)
â”œâ”€â”€ best_model.joblib       ğŸ“¦ Trained model artifact
â”œâ”€â”€ incident_event_log.csv  ğŸ“„ Input dataset
â”œâ”€â”€ requirements.txt        ğŸ“Œ Dependencies
â””â”€â”€ RiskRadar_Report.ipynb  ğŸ“˜ Detailed project explanation (notebook)
```

Each module has a clear responsibility so the code stays readable and easy to reason about.

---

## ğŸ”— How the pieces fit together

### 1ï¸âƒ£ `data_processing.py`
- Reads the raw event log
- Handles missing values and timestamps
- Aggregates event-level data into **incident-level summaries**

ğŸ‘‰ Output: one clean row per incident

---

### 2ï¸âƒ£ `feature_engineering.py`
- Converts summaries into numeric features
- Examples:
  - Total number of events
  - Reassignment count
  - Reopen count
  - Average gaps between events

ğŸ‘‰ Output: model-ready feature matrix

---

### 3ï¸âƒ£ `model_training.py`
- Trains a classification model
- Applies **probability calibration**
- Saves the trained model to disk

ğŸ‘‰ Output: `best_model.joblib`

---

### 4ï¸âƒ£ `decision_logic.py`
- Maps probabilities to **risk bands**
- Attaches **recommended actions**
- Keeps business logic separate from ML code

ğŸ‘‰ Output: interpretable risk decisions

---

### 5ï¸âƒ£ `llm_explainer.py`
- Generates short explanations
- Uses only computed facts (no guessing)
- Optional layer â€” model works without it

ğŸ‘‰ Output: human-friendly explanations

---

### 6ï¸âƒ£ `app.py`
- Loads the trained model and data
- Runs predictions
- Displays dashboard, tables, filters, and downloads

ğŸ‘‰ This is what the user actually interacts with

---

## ğŸ“Š Dashboard & Visuals (what they show)

Each visual answers a specific operational question:

- ğŸ“ˆ **Risk probability distribution**  
  Shows how incidents are spread across low â†’ high risk.

- ğŸš¦ **Risk band counts**  
  Quick view of how many incidents need attention.

- ğŸ‘¥ **Top risky assignment groups**  
  Highlights teams where SLA breaches are more common.

- ğŸ—‚ï¸ **Top risky categories**  
  Identifies problem areas in the IT landscape.

- ğŸ”¥ **Priority Ã— Risk band heatmap**  
  Shows where risk concentrates by priority level â€” useful for quick triage.

- ğŸ¯ **Calibration curve**  
  Checks whether predicted probabilities align with actual outcomes.

Each chart is explained inside the dashboard in simple language so a new user isnâ€™t lost.

---

## â–¶ï¸ Demo Video

ğŸ“¹ **Demo walkthrough (to be added)**

Planned demo will show:
- Uploading the dataset
- Exploring the dashboard
- Understanding risk scores
- Downloading predictions

*(Link will be added once recorded)*

---

## ğŸš€ How to Run

### Install dependencies
```bash
pip install -r requirements.txt
```

### Train the model
```bash
python run_train.py
```

### Launch the dashboard
```bash
streamlit run app.py
```

---

## ğŸ“¤ Outputs

- Interactive dashboard in browser
- Sortable & filterable incident list
- Incident-level risk details
- Downloadable CSV with predictions

---

## ğŸ§ª Project Level

**Intermediate â†’ Advanced**

This project demonstrates:
- Applied machine learning
- Feature engineering from real event logs
- Probability calibration
- Clear separation of concerns
- Practical decision-support design

---

## ğŸ“ Final Notes

RiskRadar is built to be:
- Understandable
- Explainable
- Useful in real operations

Every score, chart, and recommendation can be traced back to actual incident behavior â€” no black boxes, no magic.

