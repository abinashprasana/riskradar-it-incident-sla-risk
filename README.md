<div align="center">

# ğŸ›°ï¸ RiskRadar â€” IT Incident SLA Breach Risk (Decision Support)
### ML Risk Scoring â€¢ Visual Dashboard â€¢ Human-Readable Explanations â€¢ Exportable Results

<p>
  <img src="https://img.shields.io/badge/Python-3.9%2B-blue?logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/App-Streamlit-FF4B4B?logo=streamlit&logoColor=white" />
  <img src="https://img.shields.io/badge/ML-scikit--learn-F7931E?logo=scikitlearn&logoColor=white" />
  <img src="https://img.shields.io/badge/Data-pandas-150458?logo=pandas&logoColor=white" />
  <img src="https://img.shields.io/badge/Status-Completed-brightgreen" />
</p>

</div>

---

## ğŸ‘€ What this is

**RiskRadar** is a small decision-support app for **IT incident triage**.

You upload an incident event log â†’ the app **summarises each incident** into useful features â†’ a trained ML model predicts the **probability of SLA breach** â†’ the app groups incidents into **risk bands** (High/Medium/Low), gives a **recommended next action**, and shows a **dashboard with visuals** so itâ€™s easy to spot patterns.

Itâ€™s meant to be practical: something you can demo in an interview and also explain clearly.

---

## âœ… Why this project is useful

In real IT operations, teams donâ€™t just need a prediction â€” they need:
- **a risk score** they can trust (probability, not just labels)
- **a reason / explanation** in plain language (based on computed signals)
- **visibility across the queue** (dashboard + filters)
- **a way to export results** (CSV) for reporting / handover

Thatâ€™s basically what RiskRadar is doing.

---

## âœ¨ Features

- ğŸ“ Upload **incident_event_log.csv** (event-level log)
- ğŸ§  Builds **incident-level summaries** (counts, stats, churn signals)
- ğŸ¯ Predicts **SLA breach probability** using a saved model (`best_model.joblib`)
- ğŸ§­ Converts probability â†’ **risk band** (High / Medium / Low)
- ğŸ§¾ Generates short **human-readable explanations** (grounded in computed facts)
- ğŸ“Š Dashboard visuals:
  - Risk probability distribution
  - Risk band counts
  - Top risky assignment groups (avg probability)
  - Top risky categories (avg probability)
  - ğŸ“Œ Priority Ã— Risk band heatmap (triage view)
  - ğŸ“ˆ Calibration curve (to sanity-check probability behavior)
- ğŸ” Incident list (sortable / searchable)
- ğŸ§© Incident detail view (for a single ticket)
- â¬‡ï¸ Download scored dataset as CSV

---

## ğŸ§  How the app â€œthinksâ€ (simple version)

1. **Event logs â†’ Incident summary**  
   Many rows per incident â†’ summarised into 1 row per incident.

2. **Summary features â†’ ML risk score**  
   Model predicts probability: `P(SLA_Breach = 1)`.

3. **Probability â†’ Risk band + action**  
   Example:
   - High risk â†’ escalate, reduce reassignment loops, senior review
   - Medium â†’ monitor closely, ensure proper updates
   - Low â†’ normal queue, avoid unnecessary churn

4. **Dashboard â†’ patterns**  
   Helps answer:
   - Which assignment groups are repeatedly risky?
   - Which categories tend to breach?
   - Is priority correlated with high-risk? (heatmap)
   - Are predicted probabilities roughly calibrated? (calibration plot)

---

## ğŸ§© Workflow Highlights

<details>
  <summary><b>ğŸ“¦ Data processing (event log â†’ clean types)</b></summary>

- Handles missing values safely  
- Parses time columns (best-effort)  
- Keeps only fields needed for summarisation + model scoring  
</details>

<details>
  <summary><b>ğŸ§± Feature engineering (incident-level signals)</b></summary>

Examples of signals created (depends on dataset columns available):
- total events in an incident
- max / mean change counts (status, assignment, etc.)
- reassignment / reopen churn
- priority / category / assignment group encoded safely

</details>

<details>
  <summary><b>ğŸ¯ Model scoring</b></summary>

- Loads `best_model.joblib`
- Predicts **probability** (not just 0/1)
- Applies risk band thresholds
</details>

<details>
  <summary><b>ğŸ§¾ Explanation generation</b></summary>

Explanations are generated using **computed values** only:
- probability, risk band
- churn counts / event counts
- priority/category/group patterns (when available)

No â€œmagic model reasoningâ€ claims â€” it stays grounded.
</details>

---

## ğŸ—‚ï¸ Project Structure

```text
riskradar-it-incident-sla-risk/
â”œâ”€â”€ app.py
â”œâ”€â”€ data_processing.py
â”œâ”€â”€ feature_engineering.py
â”œâ”€â”€ model_training.py
â”œâ”€â”€ decision_logic.py
â”œâ”€â”€ llm_explainer.py
â”œâ”€â”€ run_train.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ RiskRadar_Report.ipynb
â””â”€â”€ (your local files)
    â”œâ”€â”€ incident_event_log.csv          # optional locally (large file)
    â””â”€â”€ best_model.joblib               # generated after training
```

---

## ğŸ§¾ File-by-file (what each file does)

### `app.py` (main entry)
- Streamlit UI (Dashboard / Incident List / Incident Detail)
- Calls processing + feature engineering + scoring
- Renders charts and tables
- Exports scored results as CSV

### `data_processing.py`
- Loads CSV safely
- Handles missing values + type cleanup
- Prepares a clean dataframe for feature engineering

### `feature_engineering.py`
- Converts event-level data into incident-level summary features
- Produces the single-row-per-incident table used for scoring

### `model_training.py`
- Training pipeline
- Splits data, trains ML model, evaluates
- Saves best model as `best_model.joblib`

### `run_train.py`
- Small runner script to train from terminal (quick and clean)

### `decision_logic.py`
- Converts probability into:
  - `risk_band`
  - `recommended_action`
- Keeps decision rules in one place

### `llm_explainer.py`
- Generates short explanation text
- Stays grounded in computed facts (probability + summary signals)

### `RiskRadar_Report.ipynb`
- Notebook version of the project write-up / walkthrough
- Useful for explaining approach + results

---

## ğŸš€ How to Run (IDE / Terminal)

### 1) Create venv (recommended)
```bash
python -m venv .venv
```

Activate:

**Windows (PowerShell)**
```bash
.\.venv\Scripts\Activate.ps1
```

**Mac/Linux**
```bash
source .venv/bin/activate
```

### 2) Install dependencies
```bash
pip install -r requirements.txt
```

### 3) Run the app
```bash
streamlit run app.py
```

Then open the local URL Streamlit prints (usually `http://localhost:8501`).

---

## ğŸ‹ï¸ Train a model (optional)

If you donâ€™t have a model yet, train one:

```bash
python run_train.py --data incident_event_log.csv --out best_model.joblib
```

After that, run the Streamlit app and set **Model path** to `best_model.joblib`.

> If you already have `best_model.joblib`, you can skip training and just run the app.

---

## ğŸ“Š Visuals (what youâ€™re seeing)

Inside the **Dashboard**:
- **Overview**: total incidents, average predicted breach probability, counts by risk band
- **Distribution**: shows whether the queue is mostly low-risk or skewing high-risk
- **Risk band counts**: quick queue composition
- **Top risky groups/categories**: highlights where risk concentrates
- **Priority Ã— Risk heatmap**: shows where high risk clusters by priority
- **Calibration curve**: sanity check for probability behavior (not perfect, but useful)

---

## ğŸ“Œ Dataset Source & Citation

This project uses the UCI ML Repository dataset:

**Incident management process enriched event log**  
Creators: Claudio Amaral, Marcelo Fantinato, Sarajane Peres

**APA citation (from UCI)**:
> Amaral, C., Fantinato, M., & Peres, S. (2018). *Incident management process enriched event log* [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C57S4H

License noted on the UCI page: **CC BY 4.0** (please keep attribution if you redistribute).

---

## âš ï¸ Notes (practical)

- The uploaded dataset can be large â€” so the app is designed to work from a file upload.
- The model is trained on engineered features from this dataset; if you swap datasets, youâ€™ll likely need retraining.
- Explanations are â€œsafeâ€: they describe computed patterns and suggested next steps (not fake model reasoning).

---

## ğŸ§  Skills shown in this project

- Data preprocessing (real log data)
- Feature engineering (event â†’ incident summarisation)
- ML model training + probability scoring
- Decision logic layer (risk band + recommended action)
- Streamlit dashboard development
- Basic model validation visuals (calibration curve)
- Clean project structure + reproducible runs

---

## âœï¸ Author

**Abinash Prasana (Abby)**  
GitHub: `abinashprasana`
